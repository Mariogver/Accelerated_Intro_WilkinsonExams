{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  EXAM 2 ANSWERS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PROBLEM 1\n",
    "\n",
    "In order to prove that both files are in the same sequence, my idea is to retrieve the Locus column from both files and compare them. To do so, I opened the files as csv files and employed the DictReader function to read the files (as they are .tsv, it must be denoted \\t as the delimiter). Following this, the csv.writer function allows me to write on a new csv file, wich I named Ger.csv for the Germplasm.tsv file. FIrstly, I wrote \"Germplasm\" (as a header) file and closed the file. After that, I started a loop for item in agicode (where agicode is the file after the DictReader object transformation) in order to extract every row from the column \"Locus\", which after extracting, I wrote that information on the Germ.csv filw below the header.\n",
    "Did the same thing for LousGene.tsv, only changing the header.\n",
    "After both new files are created, in order to compare them is necessary to list the contents of the file, so I could extract them one by one. It was alwo necessary to enable a second loop for item to change the data type in a format readable and callable by *menuwriter.writerow([a[i], b[i]])*\n",
    "The outcome (both \"Locus\" AGI codes set as a two column file) is stored on the file Juntos.csv and printed to show the perfect correlation in the order of the sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv \n",
    "import io\n",
    "\n",
    "\n",
    "\n",
    "with open(\"Germplasm.tsv\") as csvfile:\n",
    "        agicode = csv.DictReader(csvfile, delimiter='\\t', quotechar='\"')\n",
    "        with open('Germ.csv', 'a', newline='') as csvfile:\n",
    "            menuwriter = csv.writer(csvfile, delimiter=\"\\n\", quotechar='\"')\n",
    "            menuwriter.writerow([\"Germplasm\"])\n",
    "        csvfile.close\n",
    "        for item in agicode:\n",
    "           \n",
    "           with open('Germ.csv', 'a', newline='') as csvfile:\n",
    "                menuwriter = csv.writer(csvfile, delimiter=\"\\n\", quotechar='\"')\n",
    "               \n",
    "                menuwriter.writerow([item[\"Locus\"]])\n",
    "           csvfile.close\n",
    "\n",
    "with open(\"LocusGene.tsv\") as csvfile:\n",
    "        agicode = csv.DictReader(csvfile, delimiter='\\t', quotechar='\"')\n",
    "        with open('Locus.csv', 'a', newline='') as csvfile:\n",
    "                menuwriter = csv.writer(csvfile, delimiter=\"\\n\", quotechar='\"')\n",
    "                menuwriter.writerow([\"Locus\"])\n",
    "        csvfile.close\n",
    "        for item in agicode:\n",
    "           \n",
    "           with open('Locus.csv', 'a', newline='') as csvfile:\n",
    "                menuwriter = csv.writer(csvfile, delimiter=\"\\n\", quotechar='\"')\n",
    "                menuwriter.writerow([item[\"Locus\"]])\n",
    "           csvfile.close      \n",
    "        \n",
    "i=()\n",
    "with open('Germ.csv', 'r', newline='') as csvfile: \n",
    "    Unoread = list(csv.DictReader(csvfile))\n",
    "with open('Locus.csv', 'r', newline='') as csvfile: \n",
    "    Dosread = list(csv.DictReader(csvfile))\n",
    "with open('Juntos.csv', 'a', newline='') as csvfile:\n",
    "    menuwriter = csv.writer(csvfile)\n",
    "    a =[item[\"Germplasm\"] for item in Unoread]\n",
    "    b =[item[\"Locus\"] for item in Dosread]\n",
    "    for i in range(0,len(a)):\n",
    "        menuwriter.writerow([a[i], b[i]]) \n",
    "csvfile.close\n",
    "\n",
    "\n",
    "csvfile = io.open(\"Juntos.csv\")\n",
    "for item in csvfile:\n",
    "    print(csvfile.read())\n",
    "csvfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2\n",
    "\n",
    "To crate the database, pymsql will be used. As only two tables are needed, and the .tsv files that will be used as data have the \"Locus\" column equal (as proven on Problem 1) the linkage is already 1:1, so there is no nedd for a third table. Anyway, another table will be made as a possible linkage in case it is needed.\n",
    "\n",
    "First, the connection to MYSQL is stablished from a python enviroment (docker containing mysql was started previously). mysql is called and ordered to create a new database amed Exam_2  and to show the databases list in order to confirm the newly created Exam_2. As we are not working in SQL directly, the outcomes must be selected by a *cursor.fetchall()* function and printed. Finally, the connection is closed. To have a more comprehensive explanation of each part, the code has been fragmented into sections that will be explained in detail, but technically, onece we have stablished the connection we could be ordering SQL all commands in a single (longer) code.\n",
    "Finally, connection is closed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql drop database Exam_2\n",
    "#Execute before any other code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext sql\n",
    "#%config SqlMagic.autocommit=False\n",
    "%sql mysql+pymysql://root:root@127.0.0.1:3306/mysql\n",
    "import pymysql.cursors\n",
    "\n",
    "\n",
    "connection = pymysql.connect(host='localhost',\n",
    "                             user='root',\n",
    "                             password='root',\n",
    "                             db='germplasm',\n",
    "                             charset='utf8mb4',  \n",
    "                             cursorclass=pymysql.cursors.DictCursor)\n",
    "try:\n",
    "    with connection.cursor() as cursor:\n",
    "        \n",
    "        sql = \"create database Exam_2\"\n",
    "        cursor.execute(sql)\n",
    "        sql = \"show databases\"\n",
    "        cursor.execute(sql)\n",
    "        results = cursor.fetchall()\n",
    "        print(results)\n",
    "\n",
    "finally:\n",
    "    print(\"\")\n",
    "    connection.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first table is created, wich will be te previously mentioned (and not required) linkage table. The order in the creation of the tables is usually motivated for the \"link\" we have stablished. In this particular case the link of this column is the Gen_id AUTO_INCREMENT column that gives a ID to every Locus. With this assignation, other tables with the ID or the Locus can be linked to this and so establish the kind of relationship required for a database.\n",
    "The table Gen_id will have two columns, the primary key and AUTO_INCREMENT Gene_id and the Locus (where the AGI codes are) as a varchar of no more than 20 characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = pymysql.connect(host='localhost',\n",
    "                             user='root',\n",
    "                             password='root',\n",
    "                             db='Exam_2',\n",
    "                             charset='utf8mb4',  \n",
    "                             cursorclass=pymysql.cursors.DictCursor)\n",
    "try:\n",
    "    with connection.cursor() as cursor:\n",
    "       \n",
    "        sql = \"create table Gene_id(Gene_id INTEGER NOT NULL AUTO_INCREMENT PRIMARY KEY, Locus VARCHAR(20) NOT NULL)\"\n",
    "        cursor.execute(sql)\n",
    "        \n",
    "        \n",
    "        results = cursor.fetchall()\n",
    "        print(results)\n",
    "\n",
    "finally:\n",
    "    print(\"\")\n",
    "    connection.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, the two other tables are created following the same commands (but now and in the code piece avobe, the database selected when stablishing the connection must be Exam_2) they will have the same headers as in the .tsv files, and one more in the case of he LocusGene table, as it will be linked to the Gene_id table by the Gene_id column. It is extremelly important to remember to adjust the VARCHAR () number of characters on the column phenotype, as it might be very long. I set it to 2000 to avoid any problems.\n",
    "\n",
    "The databas is then finally created, with every column accordingly described (depending on the data stored) and set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = pymysql.connect(host='localhost',\n",
    "                             user='root',\n",
    "                             password='root',\n",
    "                             db='Exam_2',\n",
    "                             charset='utf8mb4',  \n",
    "                             cursorclass=pymysql.cursors.DictCursor)\n",
    "try:\n",
    "    with connection.cursor() as cursor:\n",
    "        \n",
    "        sql = \"create table Germplasm(Locus VARCHAR(20) NOT NULL PRIMARY KEY, Germplasm VARCHAR(100) NOT NULL, Phenotype VARCHAR(2000) NOT NULL, Pubmed INTEGER NOT NULL)\"\n",
    "        cursor.execute(sql)\n",
    "        sql = \"create table LocusGene(Locus VARCHAR(20) NOT NULL PRIMARY KEY, Gene VARCHAR(20) NOT NULL, Protein_length INTEGER NOT NULL, Gene_id INTEGER NOT NULL)\"\n",
    "        cursor.execute(sql)\n",
    "       \n",
    "        \n",
    "        results = cursor.fetchall()\n",
    "        print(results)\n",
    "\n",
    "finally:\n",
    "    print(\"\")\n",
    "    connection.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3\n",
    "\n",
    "To better understand the code, it is fragmented.  To fill the database I kept using pymysql, where mysql is called by python. the INSERT INTO function of mysql allows to introduce data into the databases, more preciselly into the tables. The code below refers to the filling of the Germplasm table, with the data of the Germplasm.tsv. In order to do so, the Germplasm.tsv file is opened and readed by a DictReader function and the output stored on variable _proj_. Starting a loop for row, we call for every row in the Germplasm.tsv file, and print it. Inside that same loop, we INSERT INTO (mysql function) the table Germplasm the _*row.values()_ (all row values from the Germplasm.tsv file stored in _proj_) by means of a .format. We are able to do this because we have used DictReader, which is capable of determin what is the header (keys) and what is the values of the file. So when I stablished the columns of the table where the data was going, I was cautious to make it match the keys of the file.tsv.  After this, we simply close the connection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = pymysql.connect(host='localhost',\n",
    "                            user='root',\n",
    "                            password='root',\n",
    "                            db='Exam_2',\n",
    "                            charset='utf8mb4', \n",
    "                            cursorclass=pymysql.cursors.DictCursor)\n",
    "connection.autocommit = False\n",
    "\n",
    "try:\n",
    "    with connection.cursor() as cursor:\n",
    "        with open('Germplasm.tsv') as csvfile:\n",
    "            proj = csv.DictReader(csvfile, delimiter=\"\\t\", quotechar='\"')\n",
    "            for row in proj:\n",
    "                    print(row)\n",
    "                    sql = \"\"\"INSERT INTO Germplasm (Locus, Germplasm, Phenotype, Pubmed) values\n",
    "                     ('{}', '{}', '{}', {})\"\"\".format(*row.values())\n",
    "                    cursor.execute(sql)\n",
    "        connection.commit() \n",
    "\n",
    "    results = cursor.fetchall()\n",
    "    print(results)\n",
    "\n",
    "finally:\n",
    "    print(\"\")\n",
    "    connection.close() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_(This code below is just a \"safe point\" that drops the tables Germplasm and LocusGene to make sure no overwritting errors or doublewritting errors happen before testing any code)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = pymysql.connect(host='localhost',\n",
    "                             user='root',\n",
    "                             password='root',\n",
    "                             db='Exam_2',\n",
    "                             charset='utf8mb4',\n",
    "                             cursorclass=pymysql.cursors.DictCursor)                    \n",
    "try:\n",
    "    with connection.cursor() as cursor:\n",
    "        \n",
    "        sql =\"drop table Germplasm\"\n",
    "        cursor.execute(sql)\n",
    "        sql = \"drop table LocusGene\"\n",
    "        cursor.execute(sql)\n",
    "       \n",
    "        \n",
    "        results = cursor.fetchall()\n",
    "        print(results)\n",
    "\n",
    "finally:\n",
    "    print(\"\")\n",
    "    connection.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, I created the table Gene_id, and linked it to the Germplasm table. This was made taking from the Germplasm.tsv the same \"Locus\" data that was introduced into Germplasm. To achieve this, all that data opened with a DictReader is stored in a _genid_ variable and .fotmat-ed into the sql call command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = pymysql.connect(host='localhost',\n",
    "                            user='root',\n",
    "                            password='root',\n",
    "                            db='Exam_2',\n",
    "                            charset='utf8mb4', \n",
    "                            cursorclass=pymysql.cursors.DictCursor)\n",
    "connection.autocommit = False\n",
    "try:\n",
    "    with connection.cursor() as cursor:\n",
    "        with open('Germplasm.tsv') as csvfile:\n",
    "            ge = csv.DictReader(csvfile, delimiter=\"\\t\", quotechar='\"')\n",
    "            for row in ge:\n",
    "                print(row)\n",
    "                genid = row[\"Locus\"]\n",
    "                genid = genid.strip()\n",
    "                print(genid)\n",
    "                sql = \"\"\"INSERT INTO Gene_id (Locus) values\n",
    "                     ('{}')\"\"\".format(genid)\n",
    "                cursor.execute(sql)\n",
    "                results = cursor.fetchall()\n",
    "                print(results)\n",
    "            \n",
    "            \n",
    "    connection.commit()\n",
    "  \n",
    "\n",
    "finally:\n",
    "    print(\"\")\n",
    "    connection.close() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To properlly see if the table was done right, another call is made to sql to SELECT command  and  show the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = pymysql.connect(host='localhost',\n",
    "                             user='root',\n",
    "                             password='root',\n",
    "                             db='Exam_2',\n",
    "                             charset='utf8mb4',  \n",
    "                             cursorclass=pymysql.cursors.DictCursor)\n",
    "try:\n",
    "    with connection.cursor() as cursor:\n",
    "       \n",
    "        sql =\"SELECT * FROM Gene_id\"\n",
    "        cursor.execute(sql)\n",
    "       \n",
    "       \n",
    "        \n",
    "        results = cursor.fetchall()\n",
    "        print(results)\n",
    "\n",
    "finally:\n",
    "    print(\"\")\n",
    "    connection.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last table to be made is the LocusGene. This one is linked to the Gene_id column by a more sophisticated method. First, all \"Locus\" sequences are opened by DictRead from the LocusGene.tsv file and stored on the variable _project_ (which is the \"Locus\" row data extracted from _loc_ variable). As all AGI codes are the same and in the same sequence, a SELECT query is made on the Gene_id table to extrac every Gene id number associated to every AGI code that has been extracted from the file .tsv (all in variable _project_). These Gene ids are printed and cursor.fetchall()-ed and afterwards inserted into the LocusGene table as the variable _projid_ in a .format() manner. This all is donde inside a for row loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = pymysql.connect(host='localhost',\n",
    "                            user='root',\n",
    "                            password='root',\n",
    "                            db='Exam_2',\n",
    "                            charset='utf8mb4', \n",
    "                            cursorclass=pymysql.cursors.DictCursor)\n",
    "connection.autocommit = False\n",
    "try:\n",
    "    with connection.cursor() as cursor:\n",
    "        with open('LocusGene.tsv') as csvfile:\n",
    "            loc = csv.DictReader(csvfile, delimiter=\"\\t\", quotechar='\"' )\n",
    "            for row in loc:\n",
    "                print(row)\n",
    "                project = row[\"Locus\"]\n",
    "                project = project.strip()\n",
    "                sql = \"SELECT Gene_id FROM Gene_id WHERE Locus='{}'\".format(project)\n",
    "                cursor.execute(sql)\n",
    "                results = cursor.fetchall()\n",
    "                print(results)\n",
    "                projid = results[0][\"Gene_id\"]\n",
    "                sql = \"\"\"INSERT INTO LocusGene (Locus, Gene, Protein_length, Gene_id) values\n",
    "                ('{}', '{}',{},{})\"\"\".format(row[\"Locus\"], row [\"Gene\"], row [\"ProteinLength\"], projid)\n",
    "\n",
    "                cursor.execute(sql)\n",
    "    connection.commit() \n",
    "\n",
    "    flipflop = cursor.fetchall()\n",
    "    print(flipflop)\n",
    "\n",
    "finally:\n",
    "    print(\"\")\n",
    "    connection.close() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to inspect the complete output of the process of filling th database, a last call is made to SQL, to show all three tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = pymysql.connect(host='localhost',\n",
    "                             user='root',\n",
    "                             password='root',\n",
    "                             db='Exam_2',\n",
    "                             charset='utf8mb4',  \n",
    "                             cursorclass=pymysql.cursors.DictCursor)\n",
    "try:\n",
    "    with connection.cursor() as cursor:\n",
    "       \n",
    "        sql =\"SELECT * FROM Gene_id\"\n",
    "        cursor.execute(sql)\n",
    "        results = cursor.fetchall()\n",
    "        print(results)\n",
    "        sql =\"SELECT * FROM Germplasm\"\n",
    "        cursor.execute(sql)\n",
    "        results = cursor.fetchall()\n",
    "        print(results)\n",
    "        sql =\"SELECT * FROM LocusGene\"\n",
    "        cursor.execute(sql)\n",
    "        results = cursor.fetchall()\n",
    "        print(results)\n",
    "       \n",
    "finally:\n",
    "    print(\"\")\n",
    "    connection.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 4\n",
    "\n",
    "The first question is about making a JOIN-ed report. It was at this moment that i realized that the third table (Gen_id) was almost useless, as the 1:1 linkage between the Germplasm and LocusGene tables was more than enough to accomplish the database queries and the Problem 4s' questions.\n",
    "For this reason, I avoided to show the Gene_id table on this JOIN report.\n",
    "Connection with SQL is made, and a SELECT... query is made, followed by a WHERE condition that refers to the column Locus in both tables. This, apparently gave some problems, as the columns were named the same and when the joined table is created one of those columns changes its name to Locus_1.\n",
    "\n",
    "After that, I created a csv.file where to store the report as required in the excercise by means of the DictWriter function. The fieldnames are determined by the *results[0].keys()* data transformation, which simply makes the callable elements for the DictWriter object.\n",
    "After this, the information of the tables is totally written into the \"Report.csv\" file in a \\t delimited way and by means of the function .writerow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm \"Report.csv\" # Execute before any other code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext sql\n",
    "#%config SqlMagic.autocommit=False\n",
    "%sql mysql+pymysql://root:root@127.0.0.1:3306/mysql\n",
    "import pymysql.cursors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = pymysql.connect(host='localhost',\n",
    "                             user='root',\n",
    "                             password='root',\n",
    "                             db='Exam_2',\n",
    "                             charset='utf8mb4', \n",
    "                             cursorclass=pymysql.cursors.DictCursor)\n",
    "try:\n",
    "    with connection.cursor() as cursor:\n",
    "        \n",
    "        sql =\"SELECT * FROM Germplasm, LocusGene WHERE \\\n",
    "      Germplasm.Locus = LocusGene.Locus;\"\n",
    "        cursor.execute(sql)\n",
    "        results = cursor.fetchall()\n",
    "        print(results[0].keys())\n",
    "      \n",
    "        import csv\n",
    "        import io\n",
    "        with open('Report.csv', 'a', newline='') as csvfile:\n",
    "                dumbwriter = csv.writer(csvfile, delimiter=\" \", quotechar='\"')\n",
    "                dumbwriter.writerow(\"New Report\")\n",
    "                reportwriter = csv.DictWriter(csvfile, fieldnames=results[0].keys(), delimiter= '\\t')\n",
    "                reportwriter.writeheader()\n",
    "                for row in results:\n",
    "                    reportwriter.writerows([row])\n",
    "                    csvfile.close\n",
    "        \n",
    "finally:\n",
    "    print(\"\")\n",
    "    connection.close()\n",
    "    \n",
    "csvfile = io.open(\"Report.csv\")\n",
    "print(csvfile.read())\n",
    "csvfile.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Almost every call to SQL made during the elaboration of this code was tried and perfectioned outside the pymsql enviroment, and by direct %sql calls to SQL. For comprobation purposes, most of those calls are still visible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql use Exam_2;\n",
    "%sql SELECT * FROM Germplasm, Gene_id, LocusGene WHERE\\\n",
    "      Germplasm.Locus = LocusGene.Locus AND\\\n",
    "LocusGene.Gene_id = Gene_id.Gene_id;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To accomplish the DRY rule, I defined the function _salsa()_ to load every new report into the Repor.csv file with the parameters decided. First, a \"New report\" message is print by means of _csv.writer_ before the headedr of the new report, with a delimiter \" \" (space) for the components. Next, employing _csv.DictWriter_ the contents of the report stored in the variable _results_ are written on the csv file respecting the headers and with a \\t delimiter. This funcion was employed from now until the last question of Problem 4 to store the resuts in a single file Reports.csv. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def salsa():\n",
    "        import csv\n",
    "        import io\n",
    "        with open('Report.csv', 'a', newline='') as csvfile:\n",
    "            dumbwriter = csv.writer(csvfile, delimiter=\" \", quotechar='\"')\n",
    "            dumbwriter.writerow(\"New Report\")\n",
    "            reportwriter = csv.DictWriter(csvfile, fieldnames=results[0].keys(), delimiter= '\\t')\n",
    "            reportwriter.writeheader()\n",
    "            for row in results:\n",
    "                reportwriter.writerows([row])\n",
    "                csvfile.close"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To siolate two single rows (the genes SKOR and MAA3), two independent queries were performed on the tables LocusGene and Germplasm searching for the names of the genes (that appear as a column on LocusGene) and the rows of both tables linked by the common column Locus. The command UNION mades sure that the output of the queries is only one, as it joins queries. Finally, the function _salsa()_ is executed to store the data as previously mentioned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = pymysql.connect(host='localhost',\n",
    "                             user='root',\n",
    "                             password='root',\n",
    "                             db='Exam_2',\n",
    "                             charset='utf8mb4',  \n",
    "                             cursorclass=pymysql.cursors.DictCursor)\n",
    "try:\n",
    "    with connection.cursor() as cursor:\n",
    "       \n",
    "        sql =\"SELECT *  FROM LocusGene, Germplasm WHERE\\\n",
    "        LocusGene.Gene = 'SKOR' AND\\\n",
    "        LocusGene.Locus = Germplasm.Locus\\\n",
    "        UNION SELECT *  FROM LocusGene, Germplasm WHERE\\\n",
    "        LocusGene.Gene = 'MAA3' AND\\\n",
    "        LocusGene.Locus = Germplasm.Locus\"\n",
    "        cursor.execute(sql)\n",
    "        results = cursor.fetchall()\n",
    "        salsa()\n",
    "        \n",
    "finally:\n",
    "    print(\"\")\n",
    "    connection.close()\n",
    "    \n",
    "csvfile = io.open(\"Report.csv\")\n",
    "print(csvfile.read())\n",
    "csvfile.close()\n",
    "       \n",
    "     \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql SELECT *  FROM LocusGene, Germplasm WHERE\\\n",
    "        LocusGene.Gene = 'SKOR' AND\\\n",
    "        LocusGene.Locus = Germplasm.Locus\\\n",
    "        UNION SELECT *  FROM LocusGene, Germplasm WHERE\\\n",
    "        LocusGene.Gene = 'MAA3' AND\\\n",
    "        LocusGene.Locus = Germplasm.Locus \n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To query for a number of entries, the search command SELECT COUNT (* ) which refers to everything, counts rhe number of rows or entries indicated. In this very case, as the Locus column is equal en both Germplasm and LocusGene tables, the number of entries of that column is asked for and given as the \"Number of entries\". Correctly, the output is 32, as there were 32 AGI codes. salsa() function is also employed. Remember all outputs are stored on the Report.csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = pymysql.connect(host='localhost',\n",
    "                             user='root',\n",
    "                             password='root',\n",
    "                             db='Exam_2',\n",
    "                             charset='utf8mb4',  \n",
    "                             cursorclass=pymysql.cursors.DictCursor)\n",
    "try:\n",
    "    with connection.cursor() as cursor:\n",
    "       \n",
    "        sql =\"\"\"SELECT COUNT(*) AS \"Number of entries\" FROM Germplasm RIGHT JOIN LocusGene ON \\\n",
    "     Germplasm.Locus = LocusGene.Locus;\"\"\"\n",
    "        cursor.execute(sql)\n",
    "        results = cursor.fetchall()\n",
    "        salsa()\n",
    "        \n",
    "finally:\n",
    "    print(\"\")\n",
    "    connection.close()\n",
    "    \n",
    "csvfile = io.open(\"Report.csv\")\n",
    "print(csvfile.read())\n",
    "csvfile.close()\n",
    "       \n",
    "     \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql SELECT COUNT(*) AS \"Number of entries\" FROM Germplasm RIGHT JOIN LocusGene ON \\\n",
    "     Germplasm.Locus = LocusGene.Locus;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final question asks for the average protein size, which is denoted on the column Protein_length in the table LocusGene. AVG is a command that can be set on any SELECT query on SQL, so simply asking for the specific column (LocusGene.Portein_length) inmediately gives us the answer as an average of all INTEGERS on that column (is important to define that column as a in INTEGER column). Finally, salsa() is executed and the connection is closed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = pymysql.connect(host='localhost',\n",
    "                             user='root',\n",
    "                             password='root',\n",
    "                             db='Exam_2',\n",
    "                             charset='utf8mb4',  \n",
    "                             cursorclass=pymysql.cursors.DictCursor)\n",
    "try:\n",
    "    with connection.cursor() as cursor:\n",
    "        sql =\"\"\"SELECT AVG(LocusGene.Protein_length) FROM LocusGene;\"\"\"\n",
    "        cursor.execute(sql)\n",
    "        results = cursor.fetchall()\n",
    "        salsa()\n",
    "        \n",
    "finally:\n",
    "    print(\"\")\n",
    "    connection.close()\n",
    "    \n",
    "csvfile = io.open(\"Report.csv\")\n",
    "print(csvfile.read())\n",
    "csvfile.close()\n",
    "       \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql SELECT AVG(LocusGene.Protein_length) FROM LocusGene \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If I wanted to make a more 'readable' content for the report, instead of a csv file entirely made as a database, I would simply write the code (and change it on the required places) as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import io\n",
    "with open('Report.csv', 'r', newline='') as csvfile:\n",
    "            reportread = csv.DictReader(csvfile, delimiter= '\\t' ,fieldnames=(\"Locus\", \"Germplasm\", \"Phenotype\", \"Pubmed\", \"LocusGene.Locus\",\"Gene\",\"Protein_length\", \"Gene_id\"))\n",
    "            print(results[0])\n",
    "            for row in reportread:\n",
    "                \n",
    "                normaldict = dict(row)\n",
    "                \n",
    "                arch = \"Locus: {}, Germplasm: {}, Phenotype description: {}, Pubmed id: {}, Locus: {}, Gene name: {}, Protein length: {}, Gene id number: {} \".format(*row.values())\n",
    "                print(arch)\n",
    "#\"Name: {} with age {}\".format(*row.values()))\n",
    "#sentence = str(''.join([\"Name: \", name, \" \\tAge: \", age, \"\\tDo we know this person? \", known]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
